{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARS Analysis\n",
    "\n",
    "Written by Domas Budrys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 1 and general output data\n",
    "\n",
    "import os.path\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "total_all_days = 0\n",
    "total_all_days = []\n",
    "\n",
    "total_fatal=0\n",
    "total_fatal = []\n",
    "\n",
    "def outputData1(state_id, pathFile):\n",
    "    state = []\n",
    "    name = []\n",
    "    pop_estimate = []\n",
    "\n",
    "    pathname = os.path.join(\"FARS\", \"nst-est2017-alldata.csv\")\n",
    "    #Opening nst-est2017-alldata.csv to get state IDs and names\n",
    "    with open(pathname) as dataIn:  \n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            state.append(row['STATE'])\n",
    "            name.append(row['NAME'])\n",
    "            pop_estimate.append(row['POPESTIMATE2016'])\n",
    "\n",
    "    # Indexing\n",
    "    state_index = state.index(state_id)\n",
    "    state_name = name[state_index]\n",
    "    state_pop = pop_estimate[state_index]\n",
    "\n",
    "    \n",
    "    #st_case_column = []\n",
    "    st_day_week_column = []\n",
    "\n",
    "   \n",
    "\n",
    "    pathname = os.path.join('FARS', pathFile)\n",
    "\n",
    "    with open(pathname) as dataIn:\n",
    "\n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            \n",
    "            st_day_week_column.append(row['DAY_WEEK'])\n",
    "            \n",
    "            #To count all days QUESTION 2\n",
    "            total_all_days.append(row['DAY_WEEK'])\n",
    "            \n",
    "            #To count total fatalities Question 7\n",
    "            total_fatal.append(row['MAN_COLL'])\n",
    "\n",
    "    week_day_names = []\n",
    "    #change each each number of the day to the name of the day\n",
    "    for day in st_day_week_column:\n",
    "        if (day == '1'):\n",
    "            day = \"Sunday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '2'):\n",
    "            day = \"Monday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '3'):\n",
    "            day = \"Tuesday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '4'):\n",
    "            day = \"Wednesday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '5'):\n",
    "            day = \"Thursday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '6'):\n",
    "            day = \"Friday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '7'):\n",
    "            day = \"Saturday\"\n",
    "            week_day_names.append(day)\n",
    "        else:\n",
    "            day = None\n",
    "            \n",
    "    #collections.Counter is used to display the most common one\n",
    "    display_count = []\n",
    "    for i in collections.Counter(week_day_names).most_common(1):\n",
    "        display_count += i\n",
    "   \n",
    "    #output string\n",
    "    output_days = state_name + \": Day(\" + display_count[0]+\")\", \"Count(\" + str(display_count[1]) + \")\"\n",
    "    \n",
    "    return output_days\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "In this cell we create a function called *outputData* which will display data such as, which day occurs the most accidents throughout the week. This function will take in 2 variables: **state_id** and **pathFile**. **state_id** is the number which states are identified and **pathFile** is the name of the file. Then, we separately open *nst-est2017-alldata.csv* to get names of states. Then, \n",
    "\n",
    "     st_day_week_column.append(row['DAY_WEEK'])\n",
    "\n",
    "allows us to open any file specified in the fuction and assign each of the WEEK_DAY to the list. After assigning data to *st_day_week_column* list, we are able to specify which integers means which day of the week by:\n",
    "               \n",
    "    for day in st_day_week_column:\n",
    "        if (day == '1'):\n",
    "            day = \"Sunday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '2'):\n",
    "            day = \"Monday\"\n",
    "            week_day_names.append(day)\n",
    "        elif(day == '3'):\n",
    "            day = \"Tuesday\"\n",
    "            .........\n",
    "And finally, by using collections.Counter() function we are able to display top result of *week_day_names* list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1\n",
      "The day of the week that has the most accidents for each week and the count of it\n",
      "\n",
      "('Alabama: Day(Saturday)', 'Count(166)')\n",
      "('Alaska: Day(Friday)', 'Count(15)')\n",
      "('Arizona: Day(Saturday)', 'Count(150)')\n",
      "('California: Day(Saturday)', 'Count(614)')\n",
      "('Colorado: Day(Friday)', 'Count(95)')\n",
      "('Connecticut: Day(Thursday)', 'Count(50)')\n",
      "('Delaware: Day(Saturday)', 'Count(26)')\n",
      "('District of Columbia: Day(Friday)', 'Count(5)')\n",
      "('Florida: Day(Saturday)', 'Count(507)')\n",
      "('Georgia: Day(Saturday)', 'Count(258)')\n",
      "('Hawaii: Day(Saturday)', 'Count(25)')\n",
      "('Idaho: Day(Friday)', 'Count(38)')\n",
      "('Illinois: Day(Saturday)', 'Count(202)')\n",
      "('Indiana: Day(Friday)', 'Count(127)')\n",
      "('Iowa: Day(Saturday)', 'Count(65)')\n",
      "('Kansas: Day(Saturday)', 'Count(63)')\n",
      "('Kentucky: Day(Saturday)', 'Count(133)')\n",
      "('Louisiana: Day(Sunday)', 'Count(128)')\n",
      "('Maine: Day(Saturday)', 'Count(30)')\n",
      "('Maryland: Day(Saturday)', 'Count(96)')\n",
      "('Massachusetts: Day(Saturday)', 'Count(61)')\n",
      "('Michigan: Day(Saturday)', 'Count(175)')\n",
      "('Minnesota: Day(Saturday)', 'Count(58)')\n",
      "('Mississippi: Day(Saturday)', 'Count(118)')\n",
      "('Missouri: Day(Saturday)', 'Count(156)')\n",
      "('Montana: Day(Saturday)', 'Count(34)')\n",
      "('Nebraska: Day(Sunday)', 'Count(38)')\n",
      "('Nevada: Day(Saturday)', 'Count(56)')\n",
      "('New Hampshire: Day(Friday)', 'Count(26)')\n",
      "('New Jersey: Day(Saturday)', 'Count(105)')\n",
      "('New Mexico: Day(Saturday)', 'Count(69)')\n",
      "('New York: Day(Saturday)', 'Count(159)')\n",
      "('North Carolina: Day(Saturday)', 'Count(219)')\n",
      "('North Dakota: Day(Saturday)', 'Count(22)')\n",
      "('Ohio: Day(Saturday)', 'Count(194)')\n",
      "('Oklahoma: Day(Saturday)', 'Count(109)')\n",
      "('Oregon: Day(Saturday)', 'Count(76)')\n",
      "('Pennsylvania: Day(Friday)', 'Count(186)')\n",
      "('Rhode Island: Day(Thursday)', 'Count(14)')\n",
      "('South Carolina: Day(Saturday)', 'Count(182)')\n",
      "('South Dakota: Day(Saturday)', 'Count(18)')\n",
      "('Tennessee: Day(Saturday)', 'Count(187)')\n",
      "('Texas: Day(Saturday)', 'Count(604)')\n",
      "('Utah: Day(Saturday)', 'Count(44)')\n",
      "('Vermont: Day(Wednesday)', 'Count(11)')\n",
      "('Virginia: Day(Saturday)', 'Count(139)')\n",
      "('Washington: Day(Saturday)', 'Count(87)')\n",
      "('West Virginia: Day(Wednesday)', 'Count(41)')\n",
      "('Wisconsin: Day(Saturday)', 'Count(112)')\n",
      "('Wyoming: Day(Thursday)', 'Count(19)')\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1\")\n",
    "print(\"The day of the week that has the most accidents for each week and the count of it\")\n",
    "print()\n",
    "print (outputData1('1','accident_01.csv' ))\n",
    "print (outputData1('2','accident_02.csv' ))\n",
    "print (outputData1('4','accident_04.csv' ))\n",
    "print (outputData1('6','accident_06.csv' ))\n",
    "print (outputData1('8','accident_08.csv' ))\n",
    "print (outputData1('9','accident_09.csv' ))\n",
    "print (outputData1('10','accident_10.csv' ))\n",
    "\n",
    "print (outputData1('11','accident_11.csv' ))\n",
    "print (outputData1('12','accident_12.csv' ))\n",
    "print (outputData1('13','accident_13.csv' ))\n",
    "print (outputData1('15','accident_15.csv' ))\n",
    "print (outputData1('16','accident_16.csv' ))\n",
    "print (outputData1('17','accident_17.csv' ))\n",
    "print (outputData1('18','accident_18.csv' ))\n",
    "print (outputData1('19','accident_19.csv' ))\n",
    "print (outputData1('20','accident_20.csv' ))\n",
    "\n",
    "print (outputData1('21','accident_21.csv' ))\n",
    "print (outputData1('22','accident_22.csv' ))\n",
    "print (outputData1('23','accident_23.csv' ))\n",
    "print (outputData1('24','accident_24.csv' ))\n",
    "print (outputData1('25','accident_25.csv' ))\n",
    "print (outputData1('26','accident_26.csv' ))\n",
    "print (outputData1('27','accident_27.csv' ))\n",
    "print (outputData1('28','accident_28.csv' ))\n",
    "print (outputData1('29','accident_29.csv' ))\n",
    "print (outputData1('30','accident_30.csv' ))\n",
    "\n",
    "print (outputData1('31','accident_31.csv' ))\n",
    "print (outputData1('32','accident_32.csv' ))\n",
    "print (outputData1('33','accident_33.csv' ))\n",
    "print (outputData1('34','accident_34.csv' ))\n",
    "print (outputData1('35','accident_35.csv' ))\n",
    "print (outputData1('36','accident_36.csv' ))\n",
    "print (outputData1('37','accident_37.csv' ))\n",
    "print (outputData1('38','accident_38.csv' ))\n",
    "print (outputData1('39','accident_39.csv' ))\n",
    "print (outputData1('40','accident_40.csv' ))\n",
    "\n",
    "print (outputData1('41','accident_41.csv' ))\n",
    "print (outputData1('42','accident_42.csv' ))\n",
    "print (outputData1('44','accident_44.csv' ))\n",
    "print (outputData1('45','accident_45.csv' ))\n",
    "print (outputData1('46','accident_46.csv' ))\n",
    "print (outputData1('47','accident_47.csv' ))\n",
    "print (outputData1('48','accident_48.csv' ))\n",
    "print (outputData1('49','accident_49.csv' ))\n",
    "print (outputData1('50','accident_50.csv' ))\n",
    "\n",
    "print (outputData1('51','accident_51.csv' ))\n",
    "print (outputData1('53','accident_53.csv' ))\n",
    "print (outputData1('54','accident_54.csv' ))\n",
    "print (outputData1('55','accident_55.csv' ))\n",
    "print (outputData1('56','accident_56.csv' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2\n",
      "The day of the week for the USA that has the most accidents and the count of it\n",
      "\n",
      "Day: Saturday, Count (6030)\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "total_day_count = []\n",
    "\n",
    "for day in total_all_days:\n",
    "        if (day == '1'):\n",
    "            day = \"Sunday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '2'):\n",
    "            day = \"Monday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '3'):\n",
    "            day = \"Tuesday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '4'):\n",
    "            day = \"Wednesday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '5'):\n",
    "            day = \"Thursday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '6'):\n",
    "            \n",
    "            day = \"Friday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '7'):\n",
    "            day = \"Saturday\"\n",
    "            total_day_count.append(day)\n",
    "        else:\n",
    "            day = None\n",
    "                       \n",
    "total_display_count = []\n",
    "for i in collections.Counter(total_day_count).most_common(1):\n",
    "    total_display_count += i\n",
    "    \n",
    "day_display = \"Day: \"+ total_display_count[0] +\", Count (\" +  str(total_display_count[1])+\")\"\n",
    "\n",
    "print(\"Question 2\")\n",
    "print(\"The day of the week for the USA that has the most accidents and the count of it\")\n",
    "print()\n",
    "print(day_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "In order to calculate the the total number of all days and display the count of the week day when the most accidents occurred, we must assign this data to the list. We are able to do this is *outputData* function with `total_all_days.append(row['DAY_WEEK'])`. Then, with the code\n",
    "     \n",
    "      for day in total_all_days:\n",
    "        if (day == '1'):\n",
    "            day = \"Sunday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '2'):\n",
    "            day = \"Monday\"\n",
    "            total_day_count.append(day)\n",
    "        elif(day == '3'):\n",
    "        .......\n",
    " \n",
    "we are able to we to specify which integers means which day of the week. \n",
    "And finally we display the top number by using collections.Counter() function \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 3\n",
    "total_all_hours = 0\n",
    "total_all_hours = []\n",
    "\n",
    "def outputData2(state_id, pathFile):\n",
    "    state = []\n",
    "    name = [] \n",
    "\n",
    "    pathname = os.path.join(\"FARS\", \"nst-est2017-alldata.csv\")\n",
    "    #Opening nst-est2017-alldata.csv to get state IDs and names\n",
    "    with open(pathname) as dataIn:  \n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            state.append(row['STATE'])\n",
    "            name.append(row['NAME'])\n",
    "\n",
    "    # Indexing\n",
    "    state_index = state.index(state_id)\n",
    "    state_name = name[state_index]\n",
    "\n",
    "\n",
    "    #st_case_column = []\n",
    "    st_hour_column = []\n",
    "\n",
    "\n",
    "    pathname = os.path.join('FARS', pathFile)\n",
    "\n",
    "    with open(pathname) as dataIn:\n",
    "\n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "           # st_case_column.append(row['ST_CASE'])\n",
    "            st_hour_column.append(row['HOUR'])\n",
    "\n",
    "            #To count all days QUESTION 4\n",
    "            total_all_hours.append(row['HOUR'])\n",
    "\n",
    "\n",
    "    total_hour_count = []\n",
    "\n",
    "    for hour in st_hour_column:\n",
    "            if (hour == '99'):\n",
    "                hour = \"Unknown\"\n",
    "                total_hour_count.append(hour)\n",
    "            else:\n",
    "                total_hour_count.append(hour)\n",
    "\n",
    "    #collections.Counter is used to display the most common one\n",
    "    display_hour_count = []\n",
    "    for i in collections.Counter(total_hour_count).most_common(1):\n",
    "        display_hour_count += i\n",
    "\n",
    "\n",
    "    output_hours = state_name + \": Hour(\" + str(display_hour_count[0])+\")\", \"Count(\" +str(display_hour_count[1]) + \")\"\n",
    "    \n",
    "    return output_hours\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "\n",
    "outputData2() function is almost the same as outputData1() function, but it is copied to the above cell in order to provide a detailed output for the user. Several changes include, `st_hour_column.append(row['HOUR'])` which is used to append all of the HOUR data to the list **st_hour_column**. Then we create a forLoop to check if any value from HOUR column in csv file is '99' and assign value of it to 'Unknown', else we are assigning rest of the numbers as they appear:\n",
    "       \n",
    "       for hour in st_hour_column:\n",
    "            if (hour == '99'):\n",
    "                hour = \"Unknown\"\n",
    "                total_hour_count.append(hour)\n",
    "            else:\n",
    "                total_hour_count.append(hour)\n",
    "Finally, we are able to count the top 1 number by using collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3\n",
      "The hour(military time) of the day in each state that has the most accidents and the count of it\n",
      "('Alabama: Hour(16)', 'Count(55)')\n",
      "('Alaska: Hour(5)', 'Count(7)')\n",
      "('Arizona: Hour(19)', 'Count(65)')\n",
      "('California: Hour(20)', 'Count(210)')\n",
      "('Colorado: Hour(13)', 'Count(38)')\n",
      "('Connecticut: Hour(17)', 'Count(22)')\n",
      "('Delaware: Hour(21)', 'Count(10)')\n",
      "('District of Columbia: Hour(2)', 'Count(4)')\n",
      "('Florida: Hour(21)', 'Count(208)')\n",
      "('Georgia: Hour(18)', 'Count(84)')\n",
      "('Hawaii: Hour(20)', 'Count(10)')\n",
      "('Idaho: Hour(16)', 'Count(17)')\n",
      "('Illinois: Hour(16)', 'Count(64)')\n",
      "('Indiana: Hour(17)', 'Count(50)')\n",
      "('Iowa: Hour(17)', 'Count(26)')\n",
      "('Kansas: Hour(16)', 'Count(28)')\n",
      "('Kentucky: Hour(16)', 'Count(57)')\n",
      "('Louisiana: Hour(17)', 'Count(48)')\n",
      "('Maine: Hour(18)', 'Count(12)')\n",
      "('Maryland: Hour(22)', 'Count(32)')\n",
      "('Massachusetts: Hour(22)', 'Count(25)')\n",
      "('Michigan: Hour(18)', 'Count(59)')\n",
      "('Minnesota: Hour(15)', 'Count(28)')\n",
      "('Mississippi: Hour(17)', 'Count(41)')\n",
      "('Missouri: Hour(18)', 'Count(57)')\n",
      "('Montana: Hour(21)', 'Count(13)')\n",
      "('Nebraska: Hour(Unknown)', 'Count(29)')\n",
      "('Nevada: Hour(23)', 'Count(22)')\n",
      "('New Hampshire: Hour(19)', 'Count(11)')\n",
      "('New Jersey: Hour(18)', 'Count(42)')\n",
      "('New Mexico: Hour(20)', 'Count(31)')\n",
      "('New York: Hour(17)', 'Count(59)')\n",
      "('North Carolina: Hour(18)', 'Count(92)')\n",
      "('North Dakota: Hour(16)', 'Count(9)')\n",
      "('Ohio: Hour(19)', 'Count(77)')\n",
      "('Oklahoma: Hour(16)', 'Count(41)')\n",
      "('Oregon: Hour(17)', 'Count(31)')\n",
      "('Pennsylvania: Hour(17)', 'Count(64)')\n",
      "('Rhode Island: Hour(1)', 'Count(6)')\n",
      "('South Carolina: Hour(17)', 'Count(64)')\n",
      "('South Dakota: Hour(14)', 'Count(10)')\n",
      "('Tennessee: Hour(16)', 'Count(61)')\n",
      "('Texas: Hour(20)', 'Count(200)')\n",
      "('Utah: Hour(13)', 'Count(26)')\n",
      "('Vermont: Hour(15)', 'Count(6)')\n",
      "('Virginia: Hour(17)', 'Count(60)')\n",
      "('Washington: Hour(15)', 'Count(34)')\n",
      "('West Virginia: Hour(15)', 'Count(24)')\n",
      "('Wisconsin: Hour(17)', 'Count(45)')\n",
      "('Wyoming: Hour(12)', 'Count(11)')\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 3\")\n",
    "print(\"The hour(military time) of the day in each state that has the most accidents and the count of it\")\n",
    "\n",
    "print (outputData2('1','accident_01.csv' ))\n",
    "print (outputData2('2','accident_02.csv' ))\n",
    "print (outputData2('4','accident_04.csv' ))\n",
    "print (outputData2('6','accident_06.csv' ))\n",
    "print (outputData2('8','accident_08.csv' ))\n",
    "print (outputData2('9','accident_09.csv' ))\n",
    "print (outputData2('10','accident_10.csv' ))\n",
    "\n",
    "print (outputData2('11','accident_11.csv' ))\n",
    "print (outputData2('12','accident_12.csv' ))\n",
    "print (outputData2('13','accident_13.csv' ))\n",
    "print (outputData2('15','accident_15.csv' ))\n",
    "print (outputData2('16','accident_16.csv' ))\n",
    "print (outputData2('17','accident_17.csv' ))\n",
    "print (outputData2('18','accident_18.csv' ))\n",
    "print (outputData2('19','accident_19.csv' ))\n",
    "print (outputData2('20','accident_20.csv' ))\n",
    "\n",
    "print (outputData2('21','accident_21.csv' ))\n",
    "print (outputData2('22','accident_22.csv' ))\n",
    "print (outputData2('23','accident_23.csv' ))\n",
    "print (outputData2('24','accident_24.csv' ))\n",
    "print (outputData2('25','accident_25.csv' ))\n",
    "print (outputData2('26','accident_26.csv' ))\n",
    "print (outputData2('27','accident_27.csv' ))\n",
    "print (outputData2('28','accident_28.csv' ))\n",
    "print (outputData2('29','accident_29.csv' ))\n",
    "print (outputData2('30','accident_30.csv' ))\n",
    "\n",
    "print (outputData2('31','accident_31.csv' ))\n",
    "print (outputData2('32','accident_32.csv' ))\n",
    "print (outputData2('33','accident_33.csv' ))\n",
    "print (outputData2('34','accident_34.csv' ))\n",
    "print (outputData2('35','accident_35.csv' ))\n",
    "print (outputData2('36','accident_36.csv' ))\n",
    "print (outputData2('37','accident_37.csv' ))\n",
    "print (outputData2('38','accident_38.csv' ))\n",
    "print (outputData2('39','accident_39.csv' ))\n",
    "print (outputData2('40','accident_40.csv' ))\n",
    "\n",
    "print (outputData2('41','accident_41.csv' ))\n",
    "print (outputData2('42','accident_42.csv' ))\n",
    "print (outputData2('44','accident_44.csv' ))\n",
    "print (outputData2('45','accident_45.csv' ))\n",
    "print (outputData2('46','accident_46.csv' ))\n",
    "print (outputData2('47','accident_47.csv' ))\n",
    "print (outputData2('48','accident_48.csv' ))\n",
    "print (outputData2('49','accident_49.csv' ))\n",
    "print (outputData2('50','accident_50.csv' ))\n",
    "\n",
    "print (outputData2('51','accident_51.csv' ))\n",
    "print (outputData2('53','accident_53.csv' ))\n",
    "print (outputData2('54','accident_54.csv' ))\n",
    "print (outputData2('55','accident_55.csv' ))\n",
    "print (outputData2('56','accident_56.csv' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4\n",
      "The hour(military time) of the day which has the most accidents in the USA, and the count of it\n",
      "\n",
      "Hour: 18, Count (1954)\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "total_hour_count = []\n",
    "\n",
    "total_display_hour_count = []\n",
    "for i in collections.Counter(total_all_hours).most_common(1):\n",
    "    total_display_hour_count += i\n",
    "    \n",
    "\n",
    "hour_display = \"Hour: \"+ total_display_hour_count[0] +\", Count (\" +  str(total_display_hour_count[1])+\")\"\n",
    "print(\"Question 4\")\n",
    "print(\"The hour(military time) of the day which has the most accidents in the USA, and the count of it\")\n",
    "print()\n",
    "print(hour_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 \n",
    "\n",
    "To calculate value for Question 4, we use `total_all_hours.append(row['HOUR'])` in our helper function outputData2(). This statement allows to append data each time outputData2() is executed and store every value is this list. Then, we are able to retrieve the most common value by using collections.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "total_all_drunk = 0        \n",
    "total_all_drunk =[]\n",
    "\n",
    "\n",
    "def outputData3(state_id, pathFile):\n",
    "    state = []\n",
    "    name = [] \n",
    "\n",
    "    pathname = os.path.join(\"FARS\", \"nst-est2017-alldata.csv\")\n",
    "    #Opening nst-est2017-alldata.csv to get state IDs and names\n",
    "    with open(pathname) as dataIn:  \n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            state.append(row['STATE'])\n",
    "            name.append(row['NAME'])\n",
    "\n",
    "    # Indexing\n",
    "    state_index = state.index(state_id)\n",
    "    state_name = name[state_index]\n",
    "\n",
    "    drunk_column = []\n",
    "\n",
    "\n",
    "    pathname = os.path.join('FARS', pathFile)\n",
    "\n",
    "    with open(pathname) as dataIn:\n",
    "\n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            drunk_column.append(row['DRUNK_DR'])\n",
    "\n",
    "\n",
    "    drunk_column = [int(i) for i in drunk_column]\n",
    "    total_drunk_count = []\n",
    "\n",
    "    for drunk in drunk_column:\n",
    "        if (drunk > 0):\n",
    "            total_drunk_count.append(drunk)\n",
    "\n",
    "\n",
    "    drunk_percent = (sum(total_drunk_count) / len(drunk_column))*100 \n",
    "\n",
    "    \n",
    "    #Question 6    \n",
    "    total_all_drunk.append(str(drunk_percent))\n",
    "\n",
    "    output_percent = state_name + \": \" + str(round(drunk_percent, 2))+\"%\"\n",
    "\n",
    "\n",
    "    return output_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "outputData3() function is almost the same as outputData1() function, but it is copied to the above cell in order to provide a detailed output for the user. Several changes include, `drunk_column.append(row['DRUNK_DR'])` which is used to append all of the DRUNK_DR data to the list drunk_column. Then we create a forLoop to is value of **drunk_column** is more than 0:\n",
    "\n",
    "    for drunk in drunk_column:\n",
    "        if (drunk > 0):\n",
    "            total_drunk_count.append(drunk)\n",
    "\n",
    "and append all of the eligible number to new list **total_drunk_count**\n",
    "Then, to get the percentage we use `drunk_percent = (sum(total_drunk_count) / len(drunk_column))*100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 5\n",
      "Percentages of fatal accidents that involved at least one drunk driver\n",
      "\n",
      "Alabama: 14.94%\n",
      "Alaska: 46.15%\n",
      "Arizona: 23.93%\n",
      "California: 24.19%\n",
      "Colorado: 34.77%\n",
      "Connecticut: 31.67%\n",
      "Delaware: 33.62%\n",
      "District of Columbia: 38.46%\n",
      "Florida: 21.89%\n",
      "Georgia: 22.15%\n",
      "Hawaii: 25.69%\n",
      "Idaho: 28.88%\n",
      "Illinois: 27.02%\n",
      "Indiana: 17.97%\n",
      "Iowa: 26.12%\n",
      "Kansas: 20.73%\n",
      "Kentucky: 25.29%\n",
      "Louisiana: 31.25%\n",
      "Maine: 31.13%\n",
      "Maryland: 25.21%\n",
      "Massachusetts: 29.25%\n",
      "Michigan: 26.12%\n",
      "Minnesota: 27.73%\n",
      "Mississippi: 16.56%\n",
      "Missouri: 28.57%\n",
      "Montana: 48.54%\n",
      "Nebraska: 40.21%\n",
      "Nevada: 32.01%\n",
      "New Hampshire: 30.0%\n",
      "New Jersey: 22.32%\n",
      "New Mexico: 30.17%\n",
      "New York: 17.51%\n",
      "North Carolina: 28.93%\n",
      "North Dakota: 49.02%\n",
      "Ohio: 34.76%\n",
      "Oklahoma: 28.37%\n",
      "Oregon: 27.35%\n",
      "Pennsylvania: 24.17%\n",
      "Rhode Island: 37.5%\n",
      "South Carolina: 35.9%\n",
      "South Dakota: 42.72%\n",
      "Tennessee: 22.98%\n",
      "Texas: 25.62%\n",
      "Utah: 20.08%\n",
      "Vermont: 47.37%\n",
      "Virginia: 29.92%\n",
      "Washington: 32.14%\n",
      "West Virginia: 27.6%\n",
      "Wisconsin: 33.27%\n",
      "Wyoming: 29.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 5\")\n",
    "print(\"Percentages of fatal accidents that involved at least one drunk driver\")\n",
    "print()\n",
    "print (outputData3('1','accident_01.csv' ))\n",
    "print (outputData3('2','accident_02.csv' ))\n",
    "print (outputData3('4','accident_04.csv' ))\n",
    "print (outputData3('6','accident_06.csv' ))\n",
    "print (outputData3('8','accident_08.csv' ))\n",
    "print (outputData3('9','accident_09.csv' ))\n",
    "print (outputData3('10','accident_10.csv' ))\n",
    "\n",
    "print (outputData3('11','accident_11.csv' ))\n",
    "print (outputData3('12','accident_12.csv' ))\n",
    "print (outputData3('13','accident_13.csv' ))\n",
    "print (outputData3('15','accident_15.csv' ))\n",
    "print (outputData3('16','accident_16.csv' ))\n",
    "print (outputData3('17','accident_17.csv' ))\n",
    "print (outputData3('18','accident_18.csv' ))\n",
    "print (outputData3('19','accident_19.csv' ))\n",
    "print (outputData3('20','accident_20.csv' ))\n",
    "\n",
    "print (outputData3('21','accident_21.csv' ))\n",
    "print (outputData3('22','accident_22.csv' ))\n",
    "print (outputData3('23','accident_23.csv' ))\n",
    "print (outputData3('24','accident_24.csv' ))\n",
    "print (outputData3('25','accident_25.csv' ))\n",
    "print (outputData3('26','accident_26.csv' ))\n",
    "print (outputData3('27','accident_27.csv' ))\n",
    "print (outputData3('28','accident_28.csv' ))\n",
    "print (outputData3('29','accident_29.csv' ))\n",
    "print (outputData3('30','accident_30.csv' ))\n",
    "\n",
    "print (outputData3('31','accident_31.csv' ))\n",
    "print (outputData3('32','accident_32.csv' ))\n",
    "print (outputData3('33','accident_33.csv' ))\n",
    "print (outputData3('34','accident_34.csv' ))\n",
    "print (outputData3('35','accident_35.csv' ))\n",
    "print (outputData3('36','accident_36.csv' ))\n",
    "print (outputData3('37','accident_37.csv' ))\n",
    "print (outputData3('38','accident_38.csv' ))\n",
    "print (outputData3('39','accident_39.csv' ))\n",
    "print (outputData3('40','accident_40.csv' ))\n",
    "\n",
    "print (outputData3('41','accident_41.csv' ))\n",
    "print (outputData3('42','accident_42.csv' ))\n",
    "print (outputData3('44','accident_44.csv' ))\n",
    "print (outputData3('45','accident_45.csv' ))\n",
    "print (outputData3('46','accident_46.csv' ))\n",
    "print (outputData3('47','accident_47.csv' ))\n",
    "print (outputData3('48','accident_48.csv' ))\n",
    "print (outputData3('49','accident_49.csv' ))\n",
    "print (outputData3('50','accident_50.csv' ))\n",
    "\n",
    "print (outputData3('51','accident_51.csv' ))\n",
    "print (outputData3('53','accident_53.csv' ))\n",
    "print (outputData3('54','accident_54.csv' ))\n",
    "print (outputData3('55','accident_55.csv' ))\n",
    "print (outputData3('56','accident_56.csv' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6\n",
      "\n",
      "The percentage of fatal accidents in USA that involved at least one drunk driver is :  29.54%\n"
     ]
    }
   ],
   "source": [
    "#Question 6\n",
    "total_all_drunk = [float(i) for i in total_all_drunk]\n",
    "all_drunk_percent = sum(total_all_drunk) / len(total_all_drunk)\n",
    "output_drunk_percent = round(all_drunk_percent, 2)\n",
    "\n",
    "print(\"Question 6\")\n",
    "print()\n",
    "print (\"The percentage of fatal accidents in USA that involved at \"+ \n",
    "       \"least one drunk driver is : \", str(output_drunk_percent)+\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "To get the total percentage of  fatal accidents in the USA, we append all of the final percentages of each state to **total_all_drunk** in helper function outputData3(). Then, we convert each value to float number in order to output the percentage. Then we can get total percentage using: \n",
    "\n",
    "    all_drunk_percent = sum(total_all_drunk) / len(total_all_drunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 7\n",
      "\n",
      "('Not Collision with Motor Vehicle in Transport', 21010)\n",
      "('Angle', 6044)\n",
      "('Front-to-Front', 3444)\n",
      "('Front-to-Rear', 2316)\n",
      "('Sideswipe – Same Direction', 514)\n",
      "('Sideswipe – Opposite Direction', 404)\n",
      "('Other (End-Swipes and Others)', 86)\n",
      "('Unknown', 76)\n",
      "('Rear-to-Side', 32)\n",
      "('Not Reported', 23)\n",
      "('Rear-to-Rear', 2)\n"
     ]
    }
   ],
   "source": [
    "#Question 7 \n",
    "named_fatal = []\n",
    "\n",
    "for coll in total_fatal:\n",
    "    \n",
    "    if (coll == '0'):\n",
    "        coll = \"Not Collision with Motor Vehicle in Transport\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '1'):\n",
    "        coll = \"Front-to-Rear\"\n",
    "        named_fatal.append(coll)\n",
    "    \n",
    "    elif (coll == '2'):\n",
    "        coll = \"Front-to-Front\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '6'):\n",
    "        coll = \"Angle\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '7'):\n",
    "        coll = \"Sideswipe – Same Direction\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '8'):\n",
    "        coll = \"Sideswipe – Opposite Direction\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '9'):\n",
    "        coll = \"Rear-to-Side\"\n",
    "        named_fatal.append(coll)\n",
    "\n",
    "    elif (coll == '10'):\n",
    "        coll = \"Rear-to-Rear\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '11'):\n",
    "        coll = \"Other (End-Swipes and Others)\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '98'):\n",
    "        coll = \"Not Reported\"\n",
    "        named_fatal.append(coll)\n",
    "        \n",
    "    elif (coll == '99'):\n",
    "        coll = \"Unknown\"\n",
    "        named_fatal.append(coll)\n",
    "\n",
    "sorted_fatal = []\n",
    "\n",
    "print(\"Question 7\")\n",
    "print()\n",
    "\n",
    "for i in collections.Counter(named_fatal).most_common(14):\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 \n",
    "\n",
    "To store all of the data we create the list **total_fatal** in outputData1() function. Then using **total_fatal** list, we check the value of each data entry and assign the proper description of it and append to the new list called **named_fatal**. Finally, we are able print sorted list based on the count of collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 8 AND Question 9\n",
    "accidents = 0\n",
    "accidents = []\n",
    "\n",
    "drunk_pop = 0\n",
    "drunk_pop =[]\n",
    "\n",
    "def outputData4(state_id, pathFile):\n",
    "    state = []\n",
    "    name = []\n",
    "    pop_estimate = []\n",
    "\n",
    "    pathname = os.path.join(\"FARS\", \"nst-est2017-alldata.csv\")\n",
    "    #Opening nst-est2017-alldata.csv to get state IDs and names\n",
    "    with open(pathname) as dataIn:  \n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            state.append(row['STATE'])\n",
    "            name.append(row['NAME'])\n",
    "            pop_estimate.append(row['POPESTIMATE2016'])\n",
    "\n",
    "    # Indexing\n",
    "    state_index = state.index(state_id)\n",
    "    state_name = name[state_index]\n",
    "    state_pop = pop_estimate[state_index]\n",
    "\n",
    "    state_column = []\n",
    "    drunk_column = []\n",
    "\n",
    "    pathname = os.path.join('FARS', pathFile)\n",
    "\n",
    "    with open(pathname) as dataIn:\n",
    "\n",
    "        reader = csv.DictReader(dataIn)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            #to count total accidents Question 8\n",
    "            state_column.append(row['STATE'])\n",
    "     \n",
    "            #to count total drunks accidents Question 9\n",
    "            drunk_column.append(row['DRUNK_DR'])\n",
    "\n",
    "            \n",
    "    calc_each_fatal = round((len(state_column) / int(state_pop)) * 10000, 4)\n",
    "\n",
    "    #output string\n",
    "    output_fatal = state_name + \": \" , str(calc_each_fatal)\n",
    "    \n",
    "    accidents.append(output_fatal)\n",
    "    \n",
    "\n",
    "    \n",
    "    drunk_column = [int(i) for i in drunk_column]\n",
    "    \n",
    "    total_drunk_pop_count = []\n",
    "\n",
    "    for drunk in drunk_column:\n",
    "        if (drunk > 0):\n",
    "            total_drunk_pop_count.append(drunk)\n",
    "\n",
    "    \n",
    "    calc_each_drunk = round((sum(total_drunk_pop_count) / int(state_pop)) * 10000, 4)   \n",
    "    \n",
    "    output_drunk = state_name + \": \" , str(calc_each_drunk)\n",
    "    \n",
    "    drunk_pop.append(output_drunk)\n",
    "    \n",
    "    return ()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 and Question 9\n",
    "\n",
    "outputData4() function is used for Questions 8 & 9. To get the number of all accidents in the state we simply append the value of STATE column from the .csv file to **state_column** variable and then calculate the length of it. Then we have to divide it by population estimate which we have appended to **pop_estimate** and then, multiply by 10000. This will give is a percentage of specified state. The same steps are applied to solve Question 9 except the calculate the sum of DRUNK_DR because there can be more than one drunk driver involved in accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputData4('1','accident_01.csv' )\n",
    "outputData4('2','accident_02.csv' )\n",
    "outputData4('4','accident_04.csv' )\n",
    "outputData4('6','accident_06.csv' )\n",
    "outputData4('8','accident_08.csv' )\n",
    "outputData4('9','accident_09.csv' )\n",
    "outputData4('10','accident_10.csv' )\n",
    "\n",
    "outputData4('11','accident_11.csv' )\n",
    "outputData4('12','accident_12.csv' )\n",
    "outputData4('13','accident_13.csv' )\n",
    "outputData4('15','accident_15.csv' )\n",
    "outputData4('16','accident_16.csv' )\n",
    "outputData4('17','accident_17.csv' )\n",
    "outputData4('18','accident_18.csv' )\n",
    "outputData4('19','accident_19.csv' )\n",
    "outputData4('20','accident_20.csv' )\n",
    "\n",
    "outputData4('21','accident_21.csv' )\n",
    "outputData4('22','accident_22.csv' )\n",
    "outputData4('23','accident_23.csv' )\n",
    "outputData4('24','accident_24.csv' )\n",
    "outputData4('25','accident_25.csv' )\n",
    "outputData4('26','accident_26.csv' )\n",
    "outputData4('27','accident_27.csv' )\n",
    "outputData4('28','accident_28.csv' )\n",
    "outputData4('29','accident_29.csv' )\n",
    "outputData4('30','accident_30.csv' )\n",
    "\n",
    "outputData4('31','accident_31.csv' )\n",
    "outputData4('32','accident_32.csv' )\n",
    "outputData4('33','accident_33.csv' )\n",
    "outputData4('34','accident_34.csv' )\n",
    "outputData4('35','accident_35.csv' )\n",
    "outputData4('36','accident_36.csv' )\n",
    "outputData4('37','accident_37.csv' )\n",
    "outputData4('38','accident_38.csv' )\n",
    "outputData4('39','accident_39.csv' )\n",
    "outputData4('40','accident_40.csv' )\n",
    "\n",
    "outputData4('41','accident_41.csv' )\n",
    "outputData4('42','accident_42.csv' )\n",
    "outputData4('44','accident_44.csv' )\n",
    "outputData4('45','accident_45.csv' )\n",
    "outputData4('46','accident_46.csv' )\n",
    "outputData4('47','accident_47.csv' )\n",
    "outputData4('48','accident_48.csv' )\n",
    "outputData4('49','accident_49.csv' )\n",
    "outputData4('50','accident_50.csv' )\n",
    "\n",
    "outputData4('51','accident_51.csv' )\n",
    "outputData4('53','accident_53.csv' )\n",
    "outputData4('54','accident_54.csv' )\n",
    "outputData4('55','accident_55.csv' )\n",
    "outputData4('56','accident_56.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 8\n",
      "\n",
      "Sorted list of fatal accident rate per 10000 people:\n",
      "('Mississippi: ', '2.1036%')\n",
      "('Alabama: ', '1.9278%')\n",
      "('South Carolina: ', '1.8872%')\n",
      "('Kentucky: ', '1.72%')\n",
      "('New Mexico: ', '1.7167%')\n",
      "('Wyoming: ', '1.7097%')\n",
      "('Montana: ', '1.6464%')\n",
      "('Oklahoma: ', '1.5913%')\n",
      "('Louisiana: ', '1.5023%')\n",
      "('Tennessee: ', '1.4528%')\n",
      "('Missouri: ', '1.425%')\n",
      "('Florida: ', '1.4199%')\n",
      "('Idaho: ', '1.3809%')\n",
      "('Georgia: ', '1.3788%')\n",
      "('West Virginia: ', '1.3671%')\n",
      "('North Dakota: ', '1.35%')\n",
      "('North Carolina: ', '1.3272%')\n",
      "('Kansas: ', '1.3103%')\n",
      "('Arizona: ', '1.2521%')\n",
      "('Texas: ', '1.2209%')\n",
      "('Delaware: ', '1.2176%')\n",
      "('South Dakota: ', '1.1955%')\n",
      "('Indiana: ', '1.1577%')\n",
      "('Iowa: ', '1.1371%')\n",
      "('Maine: ', '1.1351%')\n",
      "('Oregon: ', '1.0915%')\n",
      "('Alaska: ', '1.0519%')\n",
      "('Nevada: ', '1.0309%')\n",
      "('Nebraska: ', '1.017%')\n",
      "('Colorado: ', '1.009%')\n",
      "('Michigan: ', '0.9866%')\n",
      "('New Hampshire: ', '0.9738%')\n",
      "('Wisconsin: ', '0.9423%')\n",
      "('Vermont: ', '0.9144%')\n",
      "('Ohio: ', '0.906%')\n",
      "('Virginia: ', '0.8581%')\n",
      "('California: ', '0.8543%')\n",
      "('Pennsylvania: ', '0.8509%')\n",
      "('Utah: ', '0.8508%')\n",
      "('Maryland: ', '0.7834%')\n",
      "('Connecticut: ', '0.7832%')\n",
      "('Illinois: ', '0.7814%')\n",
      "('Hawaii: ', '0.7629%')\n",
      "('Washington: ', '0.6922%')\n",
      "('Minnesota: ', '0.6461%')\n",
      "('New Jersey: ', '0.6337%')\n",
      "('Massachusetts: ', '0.5261%')\n",
      "('New York: ', '0.4865%')\n",
      "('Rhode Island: ', '0.4539%')\n",
      "('District of Columbia: ', '0.3799%')\n"
     ]
    }
   ],
   "source": [
    "#Question 8\n",
    "accidents_progress = 0\n",
    "accidents_progress = []\n",
    "\n",
    "for a in accidents:\n",
    "    aa = float(a[1])\n",
    "    forming= aa, a[0]\n",
    "    accidents_progress.append(forming)\n",
    "    \n",
    "sorted_states = sorted(accidents_progress, reverse=True)\n",
    "\n",
    "output_states= []\n",
    "for s in sorted_states: \n",
    "    formatted = s[1], str(s[0])+'%'\n",
    "    output_states.append(formatted)\n",
    "    \n",
    "    \n",
    "print(\"Question 8\")\n",
    "print()\n",
    "print(\"Sorted list of fatal accident rate per 10000 people:\")\n",
    "\n",
    "for i in output_states:\n",
    "    print(i )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 Continuing\n",
    "\n",
    "After getting a percentage for each state, we can take each value and split it into separate elements. Then convert numbers into float values and place those values as the first element, pushing state name to be the second. This way we are able to apply sort function to each value and assign to new list:\n",
    "\n",
    "    for a in accidents:\n",
    "    aa = float(a[1])\n",
    "    forming= aa, a[0]\n",
    "    accidents_progress.append(forming)\n",
    "    \n",
    "    sorted_states = sorted(accidents_progress, reverse=True)\n",
    "    \n",
    "Then, we create another forLoop to format values to a proper output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 9\n",
      "\n",
      "Sorted list of accidents that involded one or more drunk drivers rate per 10000 people:\n",
      "('Montana: ', '0.7991%')\n",
      "('South Carolina: ', '0.6774%')\n",
      "('North Dakota: ', '0.6618%')\n",
      "('New Mexico: ', '0.5179%')\n",
      "('South Dakota: ', '0.5107%')\n",
      "('Wyoming: ', '0.4958%')\n",
      "('Alaska: ', '0.4855%')\n",
      "('Louisiana: ', '0.4695%')\n",
      "('Oklahoma: ', '0.4514%')\n",
      "('Kentucky: ', '0.4351%')\n",
      "('Vermont: ', '0.4331%')\n",
      "('Delaware: ', '0.4094%')\n",
      "('Nebraska: ', '0.4089%')\n",
      "('Missouri: ', '0.4071%')\n",
      "('Idaho: ', '0.3988%')\n",
      "('North Carolina: ', '0.384%')\n",
      "('West Virginia: ', '0.3773%')\n",
      "('Maine: ', '0.3533%')\n",
      "('Colorado: ', '0.3508%')\n",
      "('Mississippi: ', '0.3484%')\n",
      "('Tennessee: ', '0.3339%')\n",
      "('Nevada: ', '0.33%')\n",
      "('Ohio: ', '0.3149%')\n",
      "('Wisconsin: ', '0.3135%')\n",
      "('Texas: ', '0.3128%')\n",
      "('Florida: ', '0.3108%')\n",
      "('Georgia: ', '0.3054%')\n",
      "('Arizona: ', '0.2996%')\n",
      "('Oregon: ', '0.2986%')\n",
      "('Iowa: ', '0.297%')\n",
      "('New Hampshire: ', '0.2921%')\n",
      "('Alabama: ', '0.288%')\n",
      "('Kansas: ', '0.2717%')\n",
      "('Michigan: ', '0.2577%')\n",
      "('Virginia: ', '0.2567%')\n",
      "('Connecticut: ', '0.2481%')\n",
      "('Washington: ', '0.2225%')\n",
      "('Illinois: ', '0.2111%')\n",
      "('Indiana: ', '0.208%')\n",
      "('California: ', '0.2066%')\n",
      "('Pennsylvania: ', '0.2057%')\n",
      "('Maryland: ', '0.1975%')\n",
      "('Hawaii: ', '0.196%')\n",
      "('Minnesota: ', '0.1792%')\n",
      "('Utah: ', '0.1708%')\n",
      "('Rhode Island: ', '0.1702%')\n",
      "('Massachusetts: ', '0.1539%')\n",
      "('District of Columbia: ', '0.1461%')\n",
      "('New Jersey: ', '0.1415%')\n",
      "('New York: ', '0.0852%')\n"
     ]
    }
   ],
   "source": [
    "#Question 9\n",
    "drunk_progress = 0\n",
    "drunk_progress = []\n",
    "for d in drunk_pop:\n",
    "    dd = float(d[1])\n",
    "    forming= dd, d[0]\n",
    "    drunk_progress.append(forming)\n",
    "    \n",
    "sorted_drunk = sorted(drunk_progress, reverse=True)\n",
    "\n",
    "output_drunk= []\n",
    "for dr in sorted_drunk: \n",
    "    formatted = dr[1], str(dr[0])+'%'\n",
    "    output_drunk.append(formatted)\n",
    "    \n",
    "    \n",
    "print(\"Question 9\")\n",
    "print()\n",
    "print(\"Sorted list of accidents that involded one or more drunk drivers rate per 10000 people:\")\n",
    "\n",
    "for i in output_drunk:\n",
    "    print(i )\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 Continuing\n",
    "\n",
    "After getting a percentage for each state, we can take each value and split it into separate elements. Then convert numbers into float values place those values as the first element, pushing state name to be the second. This way we are able to apply sort function to each value and assign to new list:\n",
    "\n",
    "     for d in drunk_pop:\n",
    "         dd = float(d[1])\n",
    "         forming= dd, d[0]\n",
    "         drunk_progress.append(forming)\n",
    "    \n",
    "     sorted_drunk = sorted(drunk_progress, reverse=True)\n",
    "    \n",
    "Then, we create another forLoop to format values to a proper output format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
